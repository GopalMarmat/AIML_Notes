{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50837687",
   "metadata": {},
   "source": [
    "# Random Forest - In-Depth Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc35109",
   "metadata": {},
   "source": [
    "## What is Random Forest?\n",
    "Random Forest is an ensemble learning method used for both classification and regression tasks.\n",
    "It builds multiple decision trees and merges their results for better accuracy and control over overfitting.\n",
    "\n",
    "### Key Characteristics:\n",
    "- Ensemble method (Bagging)\n",
    "- Uses bootstrapped datasets\n",
    "- Introduces feature randomness at each node split\n",
    "- Outputs: majority vote (classification) or average (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb1bcf",
   "metadata": {},
   "source": [
    "## Advantages\n",
    "- Handles large datasets efficiently\n",
    "- Works well with both categorical and numerical features\n",
    "- Reduces overfitting compared to single decision trees\n",
    "- Automatically handles missing values\n",
    "- Gives feature importance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33119ee7",
   "metadata": {},
   "source": [
    "## Disadvantages\n",
    "- Less interpretable than individual decision trees\n",
    "- Can be computationally intensive\n",
    "- Predictions are slower for large forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403eef03",
   "metadata": {},
   "source": [
    "## How Random Forest Works\n",
    "1. **Bootstrapping**: Draw multiple random samples (with replacement) from the training data.\n",
    "2. **Decision Trees**: Train a separate decision tree on each sample.\n",
    "3. **Random Feature Selection**: At each node, choose a random subset of features for the best split.\n",
    "4. **Aggregation**:\n",
    "   - Classification: Majority vote\n",
    "   - Regression: Average prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0e983",
   "metadata": {},
   "source": [
    "## Important Parameters (sklearn)\n",
    "- `n_estimators`: Number of trees in the forest\n",
    "- `max_depth`: Maximum depth of each tree\n",
    "- `min_samples_split`: Minimum samples required to split an internal node\n",
    "- `min_samples_leaf`: Minimum samples required at a leaf node\n",
    "- `max_features`: Number of features to consider at each split\n",
    "- `bootstrap`: Whether bootstrap samples are used\n",
    "- `random_state`: Controls randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fceb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Example with Iris Dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510142f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = pd.Series(clf.feature_importances_, index=iris.feature_names)\n",
    "feature_importance.sort_values().plot(kind='barh')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf135e7",
   "metadata": {},
   "source": [
    "## Use Cases\n",
    "- Credit scoring\n",
    "- Fraud detection\n",
    "- Healthcare diagnostics\n",
    "- Customer segmentation\n",
    "- Stock price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f9d17",
   "metadata": {},
   "source": [
    "## Tips for Better Performance\n",
    "- Use `GridSearchCV` or `RandomizedSearchCV` to tune hyperparameters\n",
    "- Drop irrelevant or highly correlated features\n",
    "- Use cross-validation to check generalization\n",
    "- Normalize data if used with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b804774a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Random Forest is a powerful and versatile model that provides high accuracy,\n",
    "handles both classification and regression problems, and automatically manages missing data and outliers.\n",
    "Though less interpretable than a single tree, its performance often justifies the trade-off."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
