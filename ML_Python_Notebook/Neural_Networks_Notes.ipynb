{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b20fb11",
   "metadata": {},
   "source": [
    "# üß† Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb305f",
   "metadata": {},
   "source": [
    "## üîç Neural Network\n",
    "A neural network is a set of algorithms modeled loosely after the human brain. It is designed to recognize patterns and interpret sensory data through machine perception.\n",
    "\n",
    "### üîó Key Applications:\n",
    "- Image classification\n",
    "- Natural Language Processing\n",
    "- Time series prediction\n",
    "- Fraud detection\n",
    "\n",
    "> Neural Networks are the building blocks of **Deep Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06aff77",
   "metadata": {},
   "source": [
    "## üß¨ Biological vs Artificial Neurons\n",
    "| Biological Neuron | Artificial Neuron |\n",
    "|------------------|--------------------|\n",
    "| Dendrites (input) | Input Features |\n",
    "| Cell Body (process) | Weighted Sum + Bias |\n",
    "| Axon (output) | Activation Function Output |\n",
    "\n",
    "The artificial neuron is called a **perceptron**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350f0ca",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Structure of a Neural Network\n",
    "A typical neural network contains:\n",
    "- **Input Layer** ‚Äì Receives input features.\n",
    "- **Hidden Layers** ‚Äì Intermediate layers that apply activation functions.\n",
    "- **Output Layer** ‚Äì Produces predictions.\n",
    "\n",
    "We will use `graphviz` to visualize a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa1c47",
   "metadata": {},
   "source": [
    "## üìä Activation Functions\n",
    "- **Sigmoid**: $\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
    "- **Tanh**: $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "- **ReLU**: $f(x) = \\max(0, x)$\n",
    "\n",
    "Each function introduces non-linearity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2baee6",
   "metadata": {},
   "source": [
    "## üîÅ Forward Propagation\n",
    "Given inputs $X$ and weights $W$:\n",
    "$$ Z = XW + b $$\n",
    "$$ A = \\text{Activation}(Z) $$\n",
    "\n",
    "Each layer's output becomes the next layer's input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d543c72",
   "metadata": {},
   "source": [
    "## üîÑ Backpropagation (Gradient Descent)\n",
    "- Computes gradients of the loss function with respect to weights.\n",
    "- Uses **Chain Rule** of derivatives.\n",
    "- Updates weights to reduce error:\n",
    "$$ W := W - \\alpha \\cdot \\frac{\\partial L}{\\partial W} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716eb83",
   "metadata": {},
   "source": [
    "## üéØ Loss Function\n",
    "- **MSE**: For regression.\n",
    "- **Cross Entropy**: For classification.\n",
    "\n",
    "$$ L = -[y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099739c",
   "metadata": {},
   "source": [
    "## üß™ Example: Build Neural Network using Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef36845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(784,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451b300",
   "metadata": {},
   "source": [
    "## üß† Summary\n",
    "- Neural Networks consist of interconnected layers.\n",
    "- They learn via backpropagation and gradient descent.\n",
    "- Activation functions add non-linearity.\n",
    "- Keras makes it easy to build and train deep learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
