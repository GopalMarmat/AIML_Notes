{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797a3b64",
   "metadata": {},
   "source": [
    "# Introduction to Generative AI\n",
    "\n",
    "Generative AI (Gen AI) refers to AI systems capable of generating text, images, code, audio, or other data.\n",
    "It builds upon Machine Learning and Deep Learning advancements, particularly **Transformer-based architectures**.\n",
    "\n",
    "### Evolution of AI → ML → DL → Gen AI\n",
    "- **AI**: Rule-based systems.\n",
    "- **ML**: Algorithms learn from data.\n",
    "- **DL**: Neural networks (CNNs, RNNs, Transformers) extract hierarchical patterns.\n",
    "- **Gen AI**: Leverages deep models (e.g., GPT, LLaMA, Claude) to generate human-like outputs.\n",
    "\n",
    "### Applications:\n",
    "- Text generation (ChatGPT)\n",
    "- Image generation (DALL·E, Stable Diffusion)\n",
    "- Code generation (GitHub Copilot)\n",
    "- Multimodal assistants (Vision + Language models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35735c2a",
   "metadata": {},
   "source": [
    "# Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models are deep learning models trained on massive text corpora using transformer architectures.\n",
    "\n",
    "### Core Ideas:\n",
    "- **Architecture**: Based on the Transformer (Vaswani et al. 2017).\n",
    "- **Training**: Pretraining (unsupervised) → Fine-tuning (supervised/ RLHF).\n",
    "- **Capabilities**: Reasoning, translation, summarization, Q&A.\n",
    "\n",
    "### Prompt Engineering:\n",
    "Prompt engineering is the practice of crafting effective input instructions.\n",
    "\n",
    "#### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Prompt Engineering\n",
    "prompt = \"Summarize this text in 3 bullet points: ...\"\n",
    "response = llm(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd5c7f",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "RAG combines **LLMs + external knowledge** via a retrieval system.\n",
    "\n",
    "### Workflow:\n",
    "1. **Document Ingestion** → Chunking + Embedding\n",
    "2. **Store in Vector Database** (FAISS, Pinecone, Weaviate)\n",
    "3. **Query Processing** → Retrieve top relevant chunks\n",
    "4. **LLM Augmented with Retrieved Context**\n",
    "\n",
    "This ensures outputs are *grounded* and reduce hallucinations.\n",
    "\n",
    "### Chunking Methods:\n",
    "- **Fixed-size** (e.g., 500 tokens)\n",
    "- **Recursive** (splitting by semantic units)\n",
    "- **Sliding window**\n",
    "- **Hybrid approaches**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample pseudo-code for RAG\n",
    "query = \"What is Generative AI?\"\n",
    "retrieved_docs = vector_db.similarity_search(query)\n",
    "context = \"\\n\".join(retrieved_docs)\n",
    "response = llm(f\"Answer using context: {context}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e951b6",
   "metadata": {},
   "source": [
    "# LangChain (In-depth)\n",
    "\n",
    "LangChain is a framework for developing LLM-powered applications.\n",
    "\n",
    "### Key Components:\n",
    "1. **LLMs** → interface to models (OpenAI, Anthropic, HuggingFace)\n",
    "2. **Chains** → sequences of calls (Prompt → LLM → Output)\n",
    "3. **Agents** → dynamic decision makers that choose tools\n",
    "4. **Tools** → external APIs, databases, functions\n",
    "5. **Memory** → enables stateful conversations\n",
    "\n",
    "### Example Workflow (Pseudo-code):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05680ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "template = PromptTemplate(input_variables=[\"topic\"], template=\"Write a summary about {topic}.\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=template)\n",
    "response = chain.run(\"Generative AI\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3aae44",
   "metadata": {},
   "source": [
    "# LangGraph\n",
    "\n",
    "LangGraph extends LangChain with graph-based orchestration.\n",
    "\n",
    "### Why LangGraph?\n",
    "- Handles **complex multi-step workflows**\n",
    "- Uses nodes & edges to represent LLM + tool execution\n",
    "\n",
    "### Example Use Cases:\n",
    "- Multi-document RAG pipelines\n",
    "- Complex agent reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a9498",
   "metadata": {},
   "source": [
    "# LangSmith\n",
    "\n",
    "LangSmith is a **debugging, monitoring, and evaluation** platform for LLM applications.\n",
    "\n",
    "### Features:\n",
    "- Trace LLM calls\n",
    "- Monitor performance & costs\n",
    "- Evaluate output quality\n",
    "\n",
    "### Example Workflow:\n",
    "1. Build with LangChain\n",
    "2. Deploy & monitor via LangSmith\n",
    "3. Debug prompts, latency, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b521d6",
   "metadata": {},
   "source": [
    "# Evaluation & Safety in Gen AI\n",
    "\n",
    "### Challenges:\n",
    "- **Bias**: Reflects societal biases in data\n",
    "- **Hallucinations**: LLMs generate false information\n",
    "- **Toxicity & Misuse**\n",
    "\n",
    "### Evaluation Methods:\n",
    "- Automated metrics (BLEU, ROUGE, perplexity)\n",
    "- Human evaluation (quality, factual accuracy)\n",
    "- Groundedness checks (via RAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8689dd",
   "metadata": {},
   "source": [
    "# Future of Generative AI\n",
    "\n",
    "Generative AI will continue to evolve with:\n",
    "- Multimodal capabilities (vision + text + audio)\n",
    "- Smaller yet efficient domain-specific models\n",
    "- Safer and interpretable AI systems\n",
    "- Integration with enterprise knowledge systems\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
