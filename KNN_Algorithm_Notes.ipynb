{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# K-Nearest Neighbors (KNN) Algorithm\n", "\n", "K-Nearest Neighbors (KNN) is a simple, non-parametric, instance-based learning algorithm. It stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).\n", "\n", "### Key Concepts:\n", "- **Instance-based learning**: No explicit model is trained.\n", "- **Lazy learning**: Delays the decision to generalize until a query is made.\n", "- **Distance metric**: Euclidean distance is most commonly used.\n", "- **k-value**: Number of neighbors considered.\n", "\n", "### KNN Algorithm Diagram\n", "![KNN Diagram](https://upload.wikimedia.org/wikipedia/commons/e/e7/KnnClassification.svg)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Importing Required Libraries\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.metrics import classification_report, confusion_matrix\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Dataset\n", "We'll use the Iris dataset for demonstration purposes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "iris = load_iris()\n", "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n", "df['target'] = iris.target\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exploratory Data Analysis (EDA)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.pairplot(df, hue='target')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Preprocessing\n", "- Split the dataset\n", "- Feature scaling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df.drop('target', axis=1)\n", "y = df['target']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "\n", "scaler = StandardScaler()\n", "X_train = scaler.fit_transform(X_train)\n", "X_test = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model Training using KNN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["knn = KNeighborsClassifier(n_neighbors=5)\n", "knn.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = knn.predict(X_test)\n", "print(confusion_matrix(y_test, y_pred))\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Choosing the Optimal K\n", "We use the elbow method to find the best value of `k`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["error_rate = []\n", "\n", "for i in range(1, 21):\n", "    knn = KNeighborsClassifier(n_neighbors=i)\n", "    knn.fit(X_train, y_train)\n", "    pred_i = knn.predict(X_test)\n", "    error_rate.append(np.mean(pred_i != y_test))\n", "\n", "plt.figure(figsize=(10, 6))\n", "plt.plot(range(1, 21), error_rate, marker='o', linestyle='--', color='b')\n", "plt.title('Error Rate vs. K Value')\n", "plt.xlabel('K')\n", "plt.ylabel('Error Rate')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}